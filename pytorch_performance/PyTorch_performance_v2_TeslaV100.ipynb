{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BN7Va6PVugkr"
   },
   "source": [
    "# PyTorchでの学習・推論を高速化するコツ集\n",
    "## MNISTでいろいろ試す\n",
    "### 初期設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phHwkV-Lubu5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "W36WLSNQuo3J",
    "outputId": "42a6d2a2-ceaa-477c-d6b3-a50566a92dad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch version 確認\n",
    "torch.__version__  # 1.6.0+cu101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6iUX0nTSvmgQ",
    "outputId": "617074bf-f73a-4650-d96c-3d90b12319a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU使用の確認\n",
    "# Google Colaboratoryでは「ランタイム」→「ランタイムタイムを変更」でGPUに\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  # cuda(GPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "u80XR56hMmrJ",
    "outputId": "8dbca309-01f4-4995-c4e2-595a93261fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep  8 21:42:13 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   46C    P0    26W / 300W |      2MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# GPUの確認\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlwUkx7-vCLg"
   },
   "source": [
    "### ネットワーク・モデルの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "StSi5HrHuiG_"
   },
   "outputs": [],
   "source": [
    "# 参考: https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RRYA3snHwJSa"
   },
   "source": [
    "## データセットと前処理の設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MTCGMTpvT_c"
   },
   "outputs": [],
   "source": [
    "# 前処理\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "# 訓練データ\n",
    "dataset1 = datasets.MNIST('.', train=True, download=True,\n",
    "                    transform=transform)\n",
    "\n",
    "# 検証データ\n",
    "dataset2 = datasets.MNIST('.', train=False,\n",
    "                    transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4a8mehDywci_"
   },
   "source": [
    "## 訓練と検証の関数作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qr0odUyHwfiy"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()  # 訓練モードに\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # データ取り出し\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 伝搬\n",
    "        output = model(data)\n",
    "        \n",
    "        # 損失計算とバックプロパゲーション\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gggw3Xr5xjBI"
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()  # 検証モードに\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # データ取り出し\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPaYJY-zyXWh"
   },
   "source": [
    "## 1. DataLoaderについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GDIy6NRDykbu",
    "outputId": "34623cc3-f9ac-414b-e8a1-eb11c6702da5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CPUのコア数を確認\n",
    "import os\n",
    "os.cpu_count()  # コア\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "koQGWAUW2VVY"
   },
   "outputs": [],
   "source": [
    "# 関数化\n",
    "import time\n",
    "\n",
    "def MNIST_train(optimizer, model, device, train_loader, test_loader): \n",
    "    # デフォルトで訓練\n",
    "    epochs = 1\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # 処理\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "    # かかった時間\n",
    "    print(\"=======かかった時間========\")\n",
    "    print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amy9elpU1pAS"
   },
   "source": [
    "### 1.1.1 デフォルト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチのサイズ\n",
    "mini_batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FoZOsCZUJpJK"
   },
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27p3gm3Fy5B4"
   },
   "outputs": [],
   "source": [
    "# デフォルト設定のDataLoaderの場合\n",
    "train_loader_default = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size)\n",
    "test_loader_default = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "NWxp1-Gmyjgh",
    "outputId": "f78f7d76-ddbe-4bcb-bca2-7d0154d8d712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300640\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.384494\n",
      "\n",
      "Test set: Average loss: 0.3142, Accuracy: 9019/10000 (90%)\n",
      "\n",
      "=======かかった時間========\n",
      "13.338437557220459\n"
     ]
    }
   ],
   "source": [
    "MNIST_train(optimizer, model, device, train_loader_default, test_loader_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_D9bSz71tp6"
   },
   "source": [
    "### 1.1.2 DataLoaderの引数num_workersを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frIHH3LnJr3j"
   },
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxfuXKsryhRY"
   },
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_nworker = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=os.cpu_count()) \n",
    "test_loader_nworker = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "64Tdr4iC2ACm",
    "outputId": "96ba5341-de56-47c8-a897-d024fa6bdb8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.312041\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.348364\n",
      "\n",
      "Test set: Average loss: 0.2929, Accuracy: 9104/10000 (91%)\n",
      "\n",
      "=======かかった時間========\n",
      "3.1920528411865234\n"
     ]
    }
   ],
   "source": [
    "MNIST_train(optimizer, model, device, train_loader_nworker, test_loader_nworker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "psGTwxv03SUA"
   },
   "source": [
    "### 1.1.3 DataLoaderの引数pin_memoryをTrueに設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QCybqj1JtHA"
   },
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zx3ME-OF2Dlo"
   },
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "SZnlZ4Io3hGw",
    "outputId": "66efb413-582c-4731-fb92-a971c0962c0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307807\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.334812\n",
      "\n",
      "Test set: Average loss: 0.2709, Accuracy: 9192/10000 (92%)\n",
      "\n",
      "=======かかった時間========\n",
      "13.149093866348267\n"
     ]
    }
   ],
   "source": [
    "MNIST_train(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.349822\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.194957\n",
      "\n",
      "Test set: Average loss: 0.1624, Accuracy: 9500/10000 (95%)\n",
      "\n",
      "=======かかった時間========\n",
      "3.2484610080718994\n"
     ]
    }
   ],
   "source": [
    "MNIST_train(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNRqAYMGI-Fc"
   },
   "source": [
    "## 2. torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecJE2LRYJu8L"
   },
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DMvaisboJxzC"
   },
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=False) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwxupKr33oX1"
   },
   "outputs": [],
   "source": [
    "# 関数化\n",
    "\n",
    "def MNIST_train_cudnn_benchmark_True(optimizer, model, device, train_loader, test_loader): \n",
    "    # デフォルトで訓練\n",
    "    epochs = 1\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # 追加\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 処理\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "    # かかった時間\n",
    "    print(\"=======かかった時間========\")\n",
    "    print(time.time() - start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "LRdBs4n-JTbd",
    "outputId": "14faa4f2-67f5-494a-8e7a-f5a8e63959b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.308270\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.349430\n",
      "\n",
      "Test set: Average loss: 0.3305, Accuracy: 8955/10000 (90%)\n",
      "\n",
      "=======かかった時間========\n",
      "13.220165967941284\n"
     ]
    }
   ],
   "source": [
    "MNIST_train_cudnn_benchmark_True(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxbz5UbrPAhb"
   },
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300697\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.366591\n",
      "\n",
      "Test set: Average loss: 0.2966, Accuracy: 9080/10000 (91%)\n",
      "\n",
      "=======かかった時間========\n",
      "3.2593259811401367\n"
     ]
    }
   ],
   "source": [
    "MNIST_train_cudnn_benchmark_True(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JITで単純な計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2000, 30, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / 1.41421))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2000, 3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======かかった時間========\n",
      "3.891785144805908\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(200):\n",
    "    gelu(x)\n",
    "\n",
    "# かかった時間\n",
    "print(\"=======かかった時間========\")\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def fused_gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / 1.41421))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======かかった時間========\n",
      "6.0003767013549805\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(200):\n",
    "    fused_gelu(x)\n",
    "    \n",
    "# かかった時間\n",
    "print(\"=======かかった時間========\")\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch AMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_PyTorchAMP(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()  # 訓練モードに\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # データ取り出し\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 伝搬\n",
    "        # Runs the forward pass with autocasting.\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "        \n",
    "        # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
    "        # Backward passes under autocast are not recommended.\n",
    "        # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        \n",
    "        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "        # otherwise, optimizer.step() is skipped.\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        # Updates the scale for next iteration.\n",
    "        scaler.update()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数化\n",
    "\n",
    "def MNIST_train_PyTorchAMP(optimizer, model, device, train_loader, test_loader): \n",
    "    # デフォルトで訓練\n",
    "    epochs = 1\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # 追加\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 処理\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_PyTorchAMP(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "    # かかった時間\n",
    "    print(\"=======かかった時間========\")\n",
    "    print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301629\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.326936\n",
      "\n",
      "Test set: Average loss: 0.2710, Accuracy: 9156/10000 (92%)\n",
      "\n",
      "=======かかった時間========\n",
      "13.707663774490356\n"
     ]
    }
   ],
   "source": [
    "MNIST_train_PyTorchAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.299525\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.403402\n",
      "\n",
      "Test set: Average loss: 0.2639, Accuracy: 9190/10000 (92%)\n",
      "\n",
      "=======かかった時間========\n",
      "3.2667396068573\n"
     ]
    }
   ],
   "source": [
    "MNIST_train_PyTorchAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## non_blocking=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_non_blocking_true(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()  # 訓練モードに\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # データ取り出し\n",
    "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 伝搬\n",
    "        output = model(data)\n",
    "        \n",
    "        # 損失計算とバックプロパゲーション\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_non_blocking_true(model, device, test_loader):\n",
    "    model.eval()  # 検証モードに\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # データ取り出し\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数化\n",
    "\n",
    "def MNIST_train_non_blocking_true(optimizer, model, device, train_loader, test_loader): \n",
    "    # デフォルトで訓練\n",
    "    epochs = 1\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # 追加\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 処理\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_non_blocking_true(model, device, train_loader, optimizer, epoch)\n",
    "        test_non_blocking_true(model, device, test_loader)\n",
    "\n",
    "    # かかった時間\n",
    "    print(\"=======かかった時間========\")\n",
    "    print(time.time() - start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.396553\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.180240\n",
      "\n",
      "Test set: Average loss: 0.1862, Accuracy: 9416/10000 (94%)\n",
      "\n",
      "=======かかった時間========\n",
      "13.12535572052002\n"
     ]
    }
   ],
   "source": [
    "MNIST_train_non_blocking_true(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.309985\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.308325\n",
      "\n",
      "Test set: Average loss: 0.3115, Accuracy: 8989/10000 (90%)\n",
      "\n",
      "=======かかった時間========\n",
      "13.12648320198059\n"
     ]
    }
   ],
   "source": [
    "MNIST_train(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vRY3_flJPBPZ"
   },
   "source": [
    "# APX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下は\n",
    "# https://github.com/NVIDIA/apex\n",
    "# を参考にAPXをインストールしておく\n",
    "\n",
    "#$ git clone https://github.com/NVIDIA/apex\n",
    "#$ cd apex\n",
    "#s$ pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "Fm9gZR7WLbc9",
    "outputId": "e900acde-1c9e-4e95-afb0-e865493b2348"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'apex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-dd9c3f0fd584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mapex\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopt_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'O1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'apex'"
     ]
    }
   ],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O1'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATAziU-XPX3z"
   },
   "outputs": [],
   "source": [
    "def trainAMP(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()  # 訓練モードに\n",
    "        \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # データ取り出し\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 伝搬\n",
    "        output = model(data)\n",
    "        \n",
    "        # 損失計算とバックプロパゲーション\n",
    "        loss = F.nll_loss(output, target)\n",
    "        \n",
    "        # AMP Train your model\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数化\n",
    "\n",
    "def MNIST_trainAMP(optimizer, model, device, train_loader, test_loader): \n",
    "    # デフォルトで訓練\n",
    "    epochs = 1\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # 追加\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 処理\n",
    "    for epoch in range(1, epochs+1):\n",
    "        trainAMP(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "    # かかった時間\n",
    "    print(\"=======かかった時間========\")\n",
    "    print(time.time() - start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O2'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O3'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O0'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O1'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apex\n",
    "\n",
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = apex.optimizers.FusedSGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O1'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apex\n",
    "\n",
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = apex.optimizers.FusedLAMB(model.parameters(), lr=lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O1'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = apex.optimizers.FusedSGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O1'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch_performance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
