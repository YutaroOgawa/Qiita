{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BN7Va6PVugkr"
   },
   "source": [
    "# PyTorchでの学習・推論を高速化するコツ集\n",
    "## MNISTでいろいろ試す\n",
    "### 初期設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phHwkV-Lubu5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "W36WLSNQuo3J",
    "outputId": "42a6d2a2-ceaa-477c-d6b3-a50566a92dad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch version 確認\n",
    "torch.__version__  # 1.6.0+cu101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6iUX0nTSvmgQ",
    "outputId": "617074bf-f73a-4650-d96c-3d90b12319a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU使用の確認\n",
    "# Google Colaboratoryでは「ランタイム」→「ランタイムタイムを変更」でGPUに\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  # cuda(GPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "u80XR56hMmrJ",
    "outputId": "8dbca309-01f4-4995-c4e2-595a93261fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep  7 10:35:30 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   29C    P0    22W / 300W |      2MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# GPUの確認\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlwUkx7-vCLg"
   },
   "source": [
    "### ネットワーク・モデルの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "StSi5HrHuiG_"
   },
   "outputs": [],
   "source": [
    "# 参考: https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RRYA3snHwJSa"
   },
   "source": [
    "## データセットと前処理の設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MTCGMTpvT_c"
   },
   "outputs": [],
   "source": [
    "# 前処理\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "# 訓練データ\n",
    "dataset1 = datasets.MNIST('.', train=True, download=True,\n",
    "                    transform=transform)\n",
    "\n",
    "# 検証データ\n",
    "dataset2 = datasets.MNIST('.', train=False,\n",
    "                    transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4a8mehDywci_"
   },
   "source": [
    "## 訓練と検証の関数作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qr0odUyHwfiy"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()  # 訓練モードに\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # データ取り出し\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 伝搬\n",
    "        output = model(data)\n",
    "        \n",
    "        # 損失計算とバックプロパゲーション\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gggw3Xr5xjBI"
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()  # 検証モードに\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # データ取り出し\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPaYJY-zyXWh"
   },
   "source": [
    "## 1. DataLoaderについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GDIy6NRDykbu",
    "outputId": "34623cc3-f9ac-414b-e8a1-eb11c6702da5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CPUのコア数を確認\n",
    "import os\n",
    "os.cpu_count()  # コア\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "koQGWAUW2VVY"
   },
   "outputs": [],
   "source": [
    "# 関数化\n",
    "import time\n",
    "\n",
    "def MNIST_train(optimizer, model, device, train_loader, test_loader): \n",
    "    # デフォルトで訓練\n",
    "    epochs = 1\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # 処理\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "    # かかった時間\n",
    "    print(\"=======かかった時間========\")\n",
    "    print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amy9elpU1pAS"
   },
   "source": [
    "### 1.1.1 デフォルト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチのサイズ\n",
    "mini_batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FoZOsCZUJpJK"
   },
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27p3gm3Fy5B4"
   },
   "outputs": [],
   "source": [
    "# デフォルト設定のDataLoaderの場合\n",
    "train_loader_default = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size)\n",
    "test_loader_default = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "NWxp1-Gmyjgh",
    "outputId": "f78f7d76-ddbe-4bcb-bca2-7d0154d8d712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301016\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.357265\n",
      "\n",
      "Test set: Average loss: 0.3339, Accuracy: 8959/10000 (90%)\n",
      "\n",
      "=======かかった時間========\n",
      "14.73472261428833\n"
     ]
    }
   ],
   "source": [
    "MNIST_train(optimizer, model, device, train_loader_default, test_loader_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_D9bSz71tp6"
   },
   "source": [
    "### 1.1.2 DataLoaderの引数num_workersを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frIHH3LnJr3j"
   },
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxfuXKsryhRY"
   },
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_nworker = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=os.cpu_count()) \n",
    "test_loader_nworker = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "64Tdr4iC2ACm",
    "outputId": "96ba5341-de56-47c8-a897-d024fa6bdb8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305990\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.317775\n",
      "\n",
      "Test set: Average loss: 0.2997, Accuracy: 9091/10000 (91%)\n",
      "\n",
      "=======かかった時間========\n",
      "3.472299337387085\n"
     ]
    }
   ],
   "source": [
    "MNIST_train(optimizer, model, device, train_loader_nworker, test_loader_nworker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "psGTwxv03SUA"
   },
   "source": [
    "### 1.1.3 DataLoaderの引数pin_memoryをTrueに設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QCybqj1JtHA"
   },
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zx3ME-OF2Dlo"
   },
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "SZnlZ4Io3hGw",
    "outputId": "66efb413-582c-4731-fb92-a971c0962c0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.293720\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.341541\n",
      "\n",
      "Test set: Average loss: 0.2946, Accuracy: 9080/10000 (91%)\n",
      "\n",
      "=======かかった時間========\n",
      "13.656277179718018\n"
     ]
    }
   ],
   "source": [
    "MNIST_train(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.374340\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.236326\n",
      "\n",
      "Test set: Average loss: 0.1847, Accuracy: 9443/10000 (94%)\n",
      "\n",
      "=======かかった時間========\n",
      "3.5092411041259766\n"
     ]
    }
   ],
   "source": [
    "MNIST_train(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNRqAYMGI-Fc"
   },
   "source": [
    "## 2. torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecJE2LRYJu8L"
   },
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DMvaisboJxzC"
   },
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=False) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwxupKr33oX1"
   },
   "outputs": [],
   "source": [
    "# 関数化\n",
    "\n",
    "def MNIST_train_cudnn_benchmark_True(optimizer, model, device, train_loader, test_loader): \n",
    "    # デフォルトで訓練\n",
    "    epochs = 1\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # 追加\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 処理\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "    # かかった時間\n",
    "    print(\"=======かかった時間========\")\n",
    "    print(time.time() - start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "LRdBs4n-JTbd",
    "outputId": "14faa4f2-67f5-494a-8e7a-f5a8e63959b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303726\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.334842\n",
      "\n",
      "Test set: Average loss: 0.3198, Accuracy: 8977/10000 (90%)\n",
      "\n",
      "=======かかった時間========\n",
      "14.470812797546387\n"
     ]
    }
   ],
   "source": [
    "MNIST_train_cudnn_benchmark_True(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxbz5UbrPAhb"
   },
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.312308\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.311656\n",
      "\n",
      "Test set: Average loss: 0.2963, Accuracy: 9073/10000 (91%)\n",
      "\n",
      "=======かかった時間========\n",
      "3.4936954975128174\n"
     ]
    }
   ],
   "source": [
    "MNIST_train_cudnn_benchmark_True(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JITで単純な計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2000, 30, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / 1.41421))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2000, 3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======かかった時間========\n",
      "9.846721410751343\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(200):\n",
    "    gelu(x)\n",
    "\n",
    "# かかった時間\n",
    "print(\"=======かかった時間========\")\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def fused_gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / 1.41421))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======かかった時間========\n",
      "6.605190277099609\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(200):\n",
    "    fused_gelu(x)\n",
    "    \n",
    "# かかった時間\n",
    "print(\"=======かかった時間========\")\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch AMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_PyTorchAMP(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()  # 訓練モードに\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # データ取り出し\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 伝搬\n",
    "        # Runs the forward pass with autocasting.\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "        \n",
    "        # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
    "        # Backward passes under autocast are not recommended.\n",
    "        # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        \n",
    "        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "        # otherwise, optimizer.step() is skipped.\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        # Updates the scale for next iteration.\n",
    "        scaler.update()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数化\n",
    "\n",
    "def MNIST_train_PyTorchAMP(optimizer, model, device, train_loader, test_loader): \n",
    "    # デフォルトで訓練\n",
    "    epochs = 1\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # 追加\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 処理\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_PyTorchAMP(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "    # かかった時間\n",
    "    print(\"=======かかった時間========\")\n",
    "    print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.314748\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.335935\n",
      "\n",
      "Test set: Average loss: 0.3094, Accuracy: 9051/10000 (91%)\n",
      "\n",
      "=======かかった時間========\n",
      "14.210430145263672\n"
     ]
    }
   ],
   "source": [
    "MNIST_train_PyTorchAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.309535\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.366289\n",
      "\n",
      "Test set: Average loss: 0.2866, Accuracy: 9116/10000 (91%)\n",
      "\n",
      "=======かかった時間========\n",
      "3.5828371047973633\n"
     ]
    }
   ],
   "source": [
    "MNIST_train_PyTorchAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vRY3_flJPBPZ"
   },
   "source": [
    "# APX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下は\n",
    "# https://github.com/NVIDIA/apex\n",
    "# を参考にAPXをインストールしておく\n",
    "\n",
    "#$ git clone https://github.com/NVIDIA/apex\n",
    "#$ cd apex\n",
    "#s$ pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "Fm9gZR7WLbc9",
    "outputId": "e900acde-1c9e-4e95-afb0-e865493b2348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O1'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATAziU-XPX3z"
   },
   "outputs": [],
   "source": [
    "def trainAMP(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()  # 訓練モードに\n",
    "        \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # データ取り出し\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 伝搬\n",
    "        output = model(data)\n",
    "        \n",
    "        # 損失計算とバックプロパゲーション\n",
    "        loss = F.nll_loss(output, target)\n",
    "        \n",
    "        # AMP Train your model\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数化\n",
    "\n",
    "def MNIST_trainAMP(optimizer, model, device, train_loader, test_loader): \n",
    "    # デフォルトで訓練\n",
    "    epochs = 1\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # 追加\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 処理\n",
    "    for epoch in range(1, epochs+1):\n",
    "        trainAMP(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "    # かかった時間\n",
    "    print(\"=======かかった時間========\")\n",
    "    print(time.time() - start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.313274\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.355386\n",
      "\n",
      "Test set: Average loss: 0.2930, Accuracy: 9081/10000 (91%)\n",
      "\n",
      "=======かかった時間========\n",
      "20.411823987960815\n"
     ]
    }
   ],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O2'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.317993\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.303060\n",
      "\n",
      "Test set: Average loss: 0.3044, Accuracy: 9072/10000 (91%)\n",
      "\n",
      "=======かかった時間========\n",
      "19.5732102394104\n"
     ]
    }
   ],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O3:  Pure FP16 training.\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O3\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : False\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O3\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : False\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n"
     ]
    }
   ],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O3'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.316994\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.331457\n",
      "\n",
      "Test set: Average loss: 0.2752, Accuracy: 9165/10000 (92%)\n",
      "\n",
      "=======かかった時間========\n",
      "19.248154401779175\n"
     ]
    }
   ],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n"
     ]
    }
   ],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O0'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.308673\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.304103\n",
      "\n",
      "Test set: Average loss: 2.3060, Accuracy: 899/10000 (9%)\n",
      "\n",
      "=======かかった時間========\n",
      "20.49299645423889\n"
     ]
    }
   ],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O1'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.312278\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.339569\n",
      "\n",
      "Test set: Average loss: 0.2769, Accuracy: 9172/10000 (92%)\n",
      "\n",
      "=======かかった時間========\n",
      "5.2218098640441895\n"
     ]
    }
   ],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apex\n",
    "\n",
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = apex.optimizers.FusedSGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O1'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307694\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.275375\n",
      "\n",
      "Test set: Average loss: 0.2994, Accuracy: 9058/10000 (91%)\n",
      "\n",
      "=======かかった時間========\n",
      "23.800689458847046\n"
     ]
    }
   ],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apex\n",
    "\n",
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = apex.optimizers.FusedLAMB(model.parameters(), lr=lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O1'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=0, pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303739\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0078125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00390625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.001953125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0009765625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00048828125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.000244140625\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0001220703125\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.103515625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0517578125e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.52587890625e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.62939453125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.814697265625e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9073486328125e-06\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5367431640625e-07\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: nan\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.76837158203125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.384185791015625e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1920928955078125e-07\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.960464477539063e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9802322387695312e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4901161193847656e-08\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.450580596923828e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.725290298461914e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.862645149230957e-09\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.313225746154785e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.656612873077393e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3283064365386963e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1641532182693481e-10\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.820766091346741e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9103830456733704e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4551915228366852e-11\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.275957614183426e-12\n",
      "\n",
      "Test set: Average loss: 23404.6933, Accuracy: 958/10000 (10%)\n",
      "\n",
      "=======かかった時間========\n",
      "25.989648580551147\n"
     ]
    }
   ],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、学習率とoptimizerを設定\n",
    "model = Net().to(device)\n",
    "lr_rate = 0.1\n",
    "optimizer = apex.optimizers.FusedSGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "# Initialization\n",
    "opt_level = 'O1'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダー\n",
    "train_loader_pin_memory = torch.utils.data.DataLoader(dataset1,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True) \n",
    "test_loader_pin_memory = torch.utils.data.DataLoader(dataset2,batch_size=mini_batch_size, num_workers=os.cpu_count(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305610\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.259592\n",
      "\n",
      "Test set: Average loss: 0.3770, Accuracy: 8745/10000 (87%)\n",
      "\n",
      "=======かかった時間========\n",
      "6.696407318115234\n"
     ]
    }
   ],
   "source": [
    "MNIST_trainAMP(optimizer, model, device, train_loader_pin_memory, test_loader_pin_memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch_performance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
